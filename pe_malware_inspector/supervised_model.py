import pandas as pd
import numpy as np
import tabulate
import warnings
warnings.filterwarnings("ignore")
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score

# Load the dataset
dataframe = pd.read_csv("/home/rashmin/Desktop/pe_malware_inspector/data/features.csv", usecols=["label", "size_image", "size_code", "size_uninit", "pe_majorlink", "pe_minorlink", "pe_driver", "pe_exe", "pe_dll", "pe_char", "debug_size", "major_version", "minor_version", "iat_rva", "export_size", "check_sum", "generated_check_sum", "virtual_address", "virtual_size", "number_of_sections", "number_of_rva_and_sizes", "total_size_pe"])

# Split the dataset into labels and features
labels = np.array(dataframe['label'])
features = dataframe.drop('label', axis=1)

# Split the data into training and testing sets
train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.25, random_state=42)

# Initialize and train different classifiers
classifiers = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=5),
    "XGBoost": XGBClassifier(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "AdaBoost": AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=42), n_estimators=50, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, random_state=42)
}

results = {}

for clf_name, clf in classifiers.items():
    clf.fit(train_features, train_labels)  # Train the classifier
    predictions = clf.predict(test_features)  # Predict using the test data
    
    # Calculate metrics
    accuracy = accuracy_score(test_labels, predictions)
    recall = recall_score(test_labels, predictions, average='macro')
    f1 = f1_score(test_labels, predictions, average='macro')
    precision = precision_score(test_labels, predictions, average='macro')
    
    # Store the results
    results[clf_name] = {
        "Accuracy": accuracy,
        "Recall": recall,
        "F1 Score": f1,
        "Precision": precision
    }

headers = ["Classifier", "Accuracy", "Recall", "F1 Score", "Precision"]
table = [[clf_name, metrics["Accuracy"], metrics["Recall"], metrics["F1 Score"], metrics["Precision"]] for clf_name, metrics in results.items()]

print(tabulate.tabulate(table, headers, tablefmt="grid"))


